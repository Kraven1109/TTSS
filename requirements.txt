# TTSS - Text-to-Speech for ComfyUI
# Multi-engine TTS with voice cloning support

# === CORE (required) ===
pyttsx3>=2.90       # Offline TTS using system voices
pydub>=0.25.1       # Audio processing and format conversion
srt>=3.5.0          # SRT subtitle parsing
soundfile>=0.12.0   # Audio file I/O

# === EDGE-TTS (recommended - online, high quality, free) ===
edge-tts>=6.1.0     # Microsoft Edge TTS API (550+ voices)

# === KOKORO (optional - lightweight neural TTS, 82M params) ===
# Fast, multi-language, works on CPU, Apache 2.0 license
# Requires espeak-ng: https://github.com/espeak-ng/espeak-ng/releases
# kokoro>=0.9.4       # Kokoro TTS
# misaki[en]          # English G2P (add [ja] for Japanese, [zh] for Chinese)

# === ORPHEUS (optional - SOTA LLM-based TTS, 3B params) ===
# Human-like speech with emotion tags: <laugh>, <sigh>, <gasp>, <chuckle>
# Uses llama.cpp backend - works on Windows/Linux/macOS without vLLM!
# orpheus-cpp                    # Orpheus TTS with llama.cpp backend
# First run downloads ~3GB GGUF model automatically
#
# For CPU inference:
#   pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
# For GPU acceleration (CUDA 12.4):
#   pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124

# === XTTS-v2 / Auralis (optional - neural TTS with voice cloning) ===
# Works with Python 3.10-3.12 (Coqui TTS requires Python <3.12)
# auralis>=0.2.8      # Auralis - XTTS-v2 wrapper
# torch>=2.0.0        # PyTorch for neural TTS

# Audio processing (pydub requires ffmpeg)
# Install ffmpeg via: conda install ffmpeg or apt install ffmpeg
scipy>=1.11.0

# Utilities
tqdm>=4.64.0
numpy>=1.24.0
