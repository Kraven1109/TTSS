# TTSS - Text-to-Speech for ComfyUI
# Multi-engine TTS with voice cloning support

# === CORE (required) ===
pyttsx3>=2.90       # Offline TTS using system voices
pydub>=0.25.1       # Audio processing and format conversion
srt>=3.5.0          # SRT subtitle parsing
soundfile>=0.12.0   # Audio file I/O

# === EDGE-TTS (recommended - online, high quality, free) ===
edge-tts>=6.1.0     # Microsoft Edge TTS API (550+ voices)

# === KOKORO (optional - lightweight neural TTS, 82M params) ===
# Fast, multi-language, works on CPU, Apache 2.0 license
# Python 3.10-3.13 compatible via ONNX Runtime
kokoro-onnx>=0.4.9    # Kokoro TTS with ONNX Runtime (auto-downloads model)
# First run downloads ~300MB model files to models/tts/

# === ORPHEUS (optional - SOTA LLM-based TTS, 3B params) ===
# Human-like speech with emotion tags: <laugh>, <sigh>, <gasp>, <chuckle>
# Uses llama.cpp backend - works on Windows/Linux/macOS without vLLM!
orpheus-cpp                    # Orpheus TTS with llama.cpp backend
# First run downloads ~3GB GGUF model automatically
#
# For CPU inference:
#   pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
# For GPU acceleration (CUDA 12.4):
#   pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124

# === CSM (optional - Conversational Speech Model, 1B params) ===
# Premium conversational TTS with voice cloning
# Uses llama.cpp backend - no HuggingFace login required!
# Downloads ggml-org/sesame-csm-1b-GGUF (~96MB) automatically
llama-cpp-python>=0.3.4       # CSM TTS with llama.cpp backend
# Install with CUDA: pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124

# Audio processing (pydub requires ffmpeg)
# Install ffmpeg via: conda install ffmpeg or apt install ffmpeg
scipy>=1.11.0

# Model downloading
huggingface-hub>=0.23.0

# Utilities
tqdm>=4.64.0
numpy>=1.24.0
