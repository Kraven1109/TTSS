# Copilot / AI Agent Instructions for TTSS

## Project Overview
TTSS is a ComfyUI custom node package for multi-engine text-to-speech synthesis.

**Supported TTS Engines:**
- `pyttsx3` - Offline system voices (SAPI/NSSpeech/espeak)
- `edge-tts` - Microsoft Edge TTS (online, 400+ voices, free)
- `coqui-tts` - Neural TTS with voice cloning (GPU)

## Project Structure
```
comfyUI-TTSS/
â”œâ”€â”€ __init__.py          # ComfyUI node registration (NODE_CLASS_MAPPINGS)
â”œâ”€â”€ nodes.py             # All node implementations (8 nodes)
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ web/ttss.js          # Frontend audio preview widget
â”œâ”€â”€ examples/            # Example ComfyUI workflows
â””â”€â”€ .github/             # GitHub configs & Copilot instructions
```

## Model Directory (ComfyUI Convention)
```
ComfyUI/models/tts/
â”œâ”€â”€ reference_audio/     # Voice cloning reference files
â”œâ”€â”€ coqui/               # Coqui TTS models
â””â”€â”€ voices/              # Custom voice models
```

## Node Classes (in nodes.py)

| Node | Purpose | Key Method | Engine Support |
|------|---------|------------|----------------|
| `TTSSTextToSpeech` | Main TTS synthesis | `synthesize()` | All 3 engines |
| `TTSSVoiceSelector` | Voice dropdown by engine | `select_voice()` | All 3 engines |
| `TTSSLoadReferenceAudio` | Load voice reference | `load_reference()` | Coqui |
| `TTSSLoadAudio` | Load audio files | `load_audio()` | - |
| `TTSSLoadSRT` | Load SRT subtitles | `load_srt()` | - |
| `TTSSPreviewAudio` | Audio preview in UI | `preview()` | - |
| `TTSSCombineAudio` | Merge audio files | `combine()` | - |
| `TTSSSaveAudio` | Save with format | `save_audio()` | - |

## Key Code Patterns

### Multi-Engine TTS Pattern
```python
def synthesize(self, text, engine, speed, voice_name="", reference_audio=None):
    if engine == "pyttsx3":
        self._synth_pyttsx3(text, output_file, voice_name, speed)
    elif engine == "edge-tts":
        self._synth_edge_tts(text, output_file, voice_name, speed)
    elif engine == "coqui-tts":
        self._synth_coqui(text, output_file, voice_name, speed, reference_audio)
```

### Dynamic Voice Loading
```python
def get_edge_tts_voices():
    """Cached voice list from edge-tts API"""
    cache_file = os.path.join(tts_models_path, "edge_voices_cache.json")
    # Returns 400+ voices, cached for 24h
```

### ComfyUI Node Pattern
```python
class MyNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {"required": {"input_name": ("TYPE", {"default": value})}}
    
    RETURN_TYPES = ("OUTPUT_TYPE",)
    FUNCTION = "method_name"
    CATEGORY = "ðŸ”Š TTSS"
    
    def method_name(self, input_name):
        return (result,)
```

## Developer Workflows

### Run Python files (ComfyUI embedded Python)
```powershell
d:\Apps\ComfyUI_portable\python_embeded\python.exe <file>.py
```

### Install dependencies
```powershell
d:\Apps\ComfyUI_portable\python_embeded\python.exe -m pip install -r requirements.txt
```

### Test node import
```powershell
d:\Apps\ComfyUI_portable\python_embeded\python.exe -c "import sys; sys.path.insert(0, 'D:/Apps/ComfyUI_portable/ComfyUI'); import folder_paths; from nodes import TTSSTextToSpeech; print('OK')"
```

## Integration with ComfyUI-LLama
TTSS works with ComfyUI-LLama for image-to-speech:
```
LoadImage â†’ ðŸ¦™ LLama Server â†’ ðŸ”Š Text to Speech â†’ ðŸŽ§ Preview Audio
```

## Editing Rules

1. Keep all node logic in `nodes.py`, registration in `__init__.py`
2. Use `folder_paths.models_dir` for model paths (ComfyUI convention)
3. Category prefix: `"ðŸ”Š TTSS"` for all nodes
4. Display name prefix: `"TTSS "` for searchability
5. Return tuples from node methods: `return (result,)`
6. Cache voice lists to avoid repeated API calls
7. Support graceful fallback when optional engines not installed

## Dependencies

**Required:**
- pyttsx3 (offline TTS)
- pydub (audio processing)
- srt (subtitle parsing)

**Optional:**
- edge-tts (Microsoft TTS)
- TTS (Coqui neural TTS)
